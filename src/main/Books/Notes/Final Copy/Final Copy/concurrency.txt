Blocking concurrency vs Non blocking concurrency
Non blocking is fater than blocking(lock based) concurrency. There is always a overhead for any type of sharing information between threads
Non blocking concurrency doesn't make use of locks
Non-blocking synchronization means that the risk of deadlocks is removed. No one thread will wait to get a lock held by another thread "forever".

java.util.concurrent.atomic package provides lock free maintenance of shared variables.
In addition, all the classes in java.util.concurrent whose names start with ConcurrentLinked or ConcurrentSkipList, provide lock-free implementation of lists, maps and sets
BlockingQueue is an interface where one thread puts objects into the queue and the other thread takes the objects from queue. 
If the queue is full then the producer thread is blocked to insert into the queue till one object is released to consumer. 
Similarly, if the queue is empty consumer thread is blocked till one object is inserted into the queue by the producer
Implementations:
ArrayBlockingQueue
DelayQueue
LinkedBlockingQueue
PriorityBlockingQueue
SynchronousQueue

ArrayBlockingQueue uses internally an array to use the queue and it has a fixed size which is given in the constructor
LinkedBlockingQueue uses nodes/linkedlist to keep track of order of elements but increases the complexity of data structure.
 It has two constructors which take queue limit and without it. If no limit is specified then Integer.maxLimit
The major implementation difference between the two data structures (synchronization-wise) is that because ArrayBlockingQueue keeps the elements in an array 
it needs only one lock to keep everything synchronized. On the other hand, LinkedBlockingQueue uses two locks, one for insertion and one for extraction. 
That happens because while ArrayBlockingQueue contains just an array, LinkedBlockingQueue contains a series of connected nodes, 
so it need to keep track of insertion and extraction at the same time.

LinkedBlockingQueue stands in between ArrayBlockingQueue and DelayQueue.
ArrayBlockingQueue is a bounded collection.
DelayQueue is an unbounded collection.
LinkedBlocingQueue is an optionally bounded collection.
PriorityBlockingQueue is an unbounded concurrent queue and implements the java.lang.comparable interface
The elements thus order themselves according to the priority decided in the comparable implementation but if we use iterator it doesn't guarantee to iterate the lements in priority order

Synchronous queue can contain a single element internally. A thread inserting an element.A thread inseting an element into the queue is blocked until another thread 
takes that element from the queue. Likewise, if a thread tries to take an element and no element is currently present, that thread is blocked until a thread insert an
 element into the queue.

ReadWrite Lock is an implementation of lock stripping technique, where two separate locks are used for read and write operation.
Since read operation doesn't modify the state of the object, it's safe to allow multiple thread access to a shared object for reading without locking, 
and by splitting one lock into read and write lock, you can easily do that. 

ReadWrite can be implemented using ReentrantReadWritLock class in the java.util.concurrent.lock package
Concurrent Hash Map uses read/write lock to lock segments of map. If number of writers are more as compared to readers then efficiency of CHM decreases as when writers
lock the read thread has to wait and all read threads are lock free

Read more: http://www.java67.com/2013/07/15-advanced-core-java-interview-questions-answers-senior-experienced-5-6-years-programmers-developers.html#ixzz4U7sdsRpt